# -*- coding: utf-8 -*-
"""Feature Engineering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-Bx9F95qq2X6yiQHyID5s4BMj0-eVkLG
"""

from google.colab import drive
drive.mount('/content/drive')
print("Drive mounted")

import pandas as pd
df = pd.read_csv('/content/drive/MyDrive/Dynamic pricing /Cleaned_Retail_Store_Inventory.csv')
print("File loaded")

df.head()

df.columns

"""**Time-Based Feature Engineering**

---

**Input Columns Used**
1. date
2. seasonality
3. holiday/promotion
"""

df['Date'] = pd.to_datetime(df['Date'])

# Day, Month, Year
df['day'] = df['Date'].dt.day
df['month'] = df['Date'].dt.month
df['year'] = df['Date'].dt.year

# Day of Week (0 = Monday, 6 = Sunday)
df['day_of_week'] = df['Date'].dt.dayofweek

# Weekend Flag
df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)

df['season'] = df['Seasonality']

df['is_holiday'] = df['Holiday/Promotion']

df.head()

"""| Feature       | Description                    |
| ------------- | ------------------------------ |
| `day`         | Day of month                   |
| `month`       | Month number                   |
| `year`        | Year                           |
| `day_of_week` | Weekday index                  |
| `is_weekend`  | Weekend flag                   |
| `season`      | Seasonal indicator             |
| `is_holiday`  | Festival / promotion indicator |

---

Price-Based Feature

Columns Used

1. Date
2. Store ID
3. Product ID
4. Price
5. Discount
6. Discounted_Price
"""

df = df.sort_values(by=['Store ID', 'Product ID', 'Date'])

df['price_lag_1'] = (
    df.groupby(['Store ID', 'Product ID'])['Price']
      .shift(1)
)

df['price_lag_7'] = (
    df.groupby(['Store ID', 'Product ID'])['Price']
      .shift(7)
)

df['price_change_pct'] = (
    (df['Price'] - df['price_lag_1']) / df['price_lag_1']
)

df['Discount']

df['discount_pct'] = df['Discount'] / 100

df['price_after_discount'] = df['Price'] * (1 - df['discount_pct'])

# Lag Prices
df = df.sort_values(by=['Store ID', 'Product ID', 'Date'])

df['price_lag_1'] = (
    df.groupby(['Store ID', 'Product ID'])['Price']
      .shift(1)
)

df['price_lag_7'] = (
    df.groupby(['Store ID', 'Product ID'])['Price']
      .shift(7)
)

# Price Change Percentage
df['price_change_pct'] = (
    (df['Price'] - df['price_lag_1']) / df['price_lag_1']
)

"""

---

Demand Features (Lag & Rolling)"""

# Sorting data
df = df.sort_values(by=['Store ID', 'Product ID', 'Date'])

# Lagged demand captures short-term and long-term memory effects.
df['sales_lag_1'] = (
    df.groupby(['Store ID', 'Product ID'])['Units Sold']
      .shift(1)
)

df['sales_lag_7'] = (
    df.groupby(['Store ID', 'Product ID'])['Units Sold']
      .shift(7)
)

df['sales_lag_30'] = (
    df.groupby(['Store ID', 'Product ID'])['Units Sold']
      .shift(30)
)

# Rolling Average Demand .
# Rolling averages smooth noise and show demand trend strength.
df['sales_roll_avg_7'] = (
    df.groupby(['Store ID', 'Product ID'])['Units Sold']
      .rolling(window=7, min_periods=1)
      .mean()
      .reset_index(level=[0,1], drop=True)
)

df['sales_roll_avg_30'] = (
    df.groupby(['Store ID', 'Product ID'])['Units Sold']
      .rolling(window=30, min_periods=1)
      .mean()
      .reset_index(level=[0,1], drop=True)
)

# Demand Volatility (Rolling Std Dev)
# Volatility shows demand stability vs unpredictability.
df['sales_volatility_7'] = (
    df.groupby(['Store ID', 'Product ID'])['Units Sold']
      .rolling(window=7, min_periods=1)
      .std()
      .reset_index(level=[0,1], drop=True)
)

df['sales_volatility_30'] = (
    df.groupby(['Store ID', 'Product ID'])['Units Sold']
      .rolling(window=30, min_periods=1)
      .std()
      .reset_index(level=[0,1], drop=True)
)

lag_cols = [
    'sales_lag_1', 'sales_lag_7', 'sales_lag_30',
    'sales_volatility_7', 'sales_volatility_30'
]

df[lag_cols] = df[lag_cols].fillna(0)

"""

---
Price Elasticity

Price Elasticity of Demand (PED) measures how sensitive demand is to price changes.

Elasticity =
% Change in Demand / % Change in Price

*   High elasticity → customers are price-sensitive
*   Low elasticity → demand is stable even if price changes

Columns Used : Units Sold , Price"""

# % Change Features
df = df.sort_values(by=['Store ID', 'Product ID', 'Date'])

df['price_pct_change'] = (
    df.groupby(['Store ID', 'Product ID'])['Price']
      .pct_change()
)

df['demand_pct_change'] = (
    df.groupby(['Store ID', 'Product ID'])['Units Sold']
      .pct_change()
)

# Raw Elasticity
df['price_elasticity'] = (
    df['demand_pct_change'] / df['price_pct_change']
)

import numpy as np
df['price_elasticity'] = df['price_elasticity'].replace([np.inf, -np.inf], np.nan)
df['price_elasticity'] = df['price_elasticity'].fillna(0)

# Smooth Elasticity
df['elasticity_7d'] = (
    df.groupby(['Store ID', 'Product ID'])['price_elasticity']
      .rolling(window=7, min_periods=1)
      .mean()
      .reset_index(level=[0,1], drop=True) )

# Aggregate Elasticity at Product Level
product_elasticity = (
    df.groupby('Product ID')['elasticity_7d']
      .mean()
      .reset_index()
      .rename(columns={'elasticity_7d': 'avg_price_elasticity'}))

def elasticity_class(e):
    if abs(e) >= 1.5:
        return 'High'
    elif abs(e) >= 0.5:
        return 'Medium'
    else:
        return 'Low'

product_elasticity['elasticity_class'] = (
    product_elasticity['avg_price_elasticity']
    .apply(elasticity_class)
)

df = df.merge(product_elasticity, on='Product ID', how='left')

"""

---

Inventory Feature Engineering

Columns Used : Inventory Level, Units Sold , Date, Product ID, Store ID

Shows how much inventory is available relative to recent demand.

Inventory Ratio = Inventory Level / Rolling Avg Demand"""

df['avg_demand_7d'] = (
    df.groupby(['Store ID', 'Product ID'])['Units Sold']
      .rolling(window=7, min_periods=1)
      .mean()
      .reset_index(level=[0,1], drop=True)
)

df['inventory_ratio'] = df['Inventory Level'] / (df['avg_demand_7d'] + 1)

"""High ratio → Overstock risk

Low ratio → Stock-out risk

Estimated number of days inventory will last at current demand.

Days Until Stock-Out = Inventory Level / Avg Daily Sales
"""

df['days_until_stockout'] = df['Inventory Level'] / (df['avg_demand_7d'] + 1)

"""Low stock if inventory < 3 days of demand"""

df['low_stock_flag'] = (df['days_until_stockout'] < 3).astype(int)

"""Overstock if inventory > 15 days of demand."""

df['overstock_flag'] = (df['days_until_stockout'] > 15).astype(int)

"""

---

Profit Feature
"""

#Profit per Unit
df['estimated_cost'] = df['Competitor Pricing']
df['profit_per_unit'] = df['Price'] - df['estimated_cost']

"""Profit Margin = Price / Profit per Unit​"""

df['profit_margin'] = df['profit_per_unit'] / df['Price']

df['daily_profit'] = df['profit_per_unit'] * df['Units Sold']

"""

---

Interaction Features"""

df['weekend_price_interaction'] = df['is_weekend'] * df['Price']

season_map = {
    'Winter': 0,
    'Spring': 1,
    'Summer': 2,
    'Autumn': 3
}

df['season_encoded'] = df['season'].map(season_map)
df['season_discount_interaction'] = df['season_encoded'] * df['discount_pct']

df['inventory_price_interaction'] = df['Inventory Level'] * df['Price']

df['lowstock_price_interaction'] = df['low_stock_flag'] * df['Price']

"""---

Categorical Encoding

One-Hot Encoding (Low Cardinality)

Using for:

Category, Region, Weather Condition , season , elasticity_class
"""

df = pd.get_dummies( df, columns=['Category', 'Region', 'Weather Condition', 'season', 'elasticity_class'] , drop_first=True )

"""Frequency Encoding (High Cardinality IDs)

For: Product ID , Store ID
"""

product_freq = df['Product ID'].value_counts()
store_freq = df['Store ID'].value_counts()

df['product_freq_enc'] = df['Product ID'].map(product_freq)
df['store_freq_enc'] = df['Store ID'].map(store_freq)

df.drop(['Product ID', 'Store ID'], axis=1, inplace=True)

df.isnull().sum().sort_values(ascending=False).head()

df.shape

"""

---

Final Cleaning"""

df.isnull().sum().sort_values(ascending=False).head()

df.fillna(0, inplace=True)

print("Duplicates before:", df.duplicated().sum())

outlier_cols = [
    'Price', 'Units Sold', 'Revenue',
    'inventory_ratio', 'days_until_stockout',
    'profit_per_unit', 'profit_margin'
]

for col in outlier_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1

    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR

    df[col] = df[col].clip(lower, upper)

df.isnull().sum().sum()

df.duplicated().sum()

df.shape

df.to_csv("PriceOptima_FeatureEngineered_Final.csv", index=False)

